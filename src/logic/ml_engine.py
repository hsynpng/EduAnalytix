import pandas as pd
import joblib
import json
import os
import sys
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_absolute_error, r2_score

# Proje dizin yapÄ±sÄ±na gÃ¶re path ayarÄ±
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))
sys.path.append(root_dir)

# Dosya YollarÄ±
MODEL_DIR = os.path.join(root_dir, "models")
MODEL_PATH = os.path.join(MODEL_DIR, "student_score_model.pkl")
ENCODERS_PATH = os.path.join(MODEL_DIR, "encoders.pkl")
METRICS_PATH = os.path.join(MODEL_DIR, "metrics.json")

# --- Ã–NEMLÄ°: YENÄ° VERÄ° SETÄ° YOLU ---
# data_balancer.py ile oluÅŸturduÄŸun dengeli veriyi kullanÄ±yoruz
BALANCED_DATA_PATH = os.path.join(root_dir, "data", "student_performance_balanced.csv")

def train_and_save_model():
    print("â³ EÄŸitim verisi yÃ¼kleniyor...")

    # 1. Veriyi YÃ¼kle (DengelenmiÅŸ CSV'den)
    if os.path.exists(BALANCED_DATA_PATH):
        print(f"ğŸ“‚ DengelenmiÅŸ veri seti kullanÄ±lÄ±yor: {BALANCED_DATA_PATH}")
        df = pd.read_csv(BALANCED_DATA_PATH)
    else:
        # EÄŸer dengelenmiÅŸ CSV yoksa hata ver ve dur (Ã‡Ã¼nkÃ¼ sorunumuzu bu Ã§Ã¶zÃ¼yor)
        print(f"âŒ HATA: {BALANCED_DATA_PATH} bulunamadÄ±!")
        print("LÃ¼tfen Ã¶nce 'data_balancer.py' scriptini Ã§alÄ±ÅŸtÄ±rarak dengeli veriyi oluÅŸturun.")
        return

    # SÃ¼tun isimlerini kÃ¼Ã§Ã¼k harfe Ã§evirerek standardizasyon saÄŸla
    df.columns = df.columns.str.strip().str.lower()

    # Gereksiz id varsa temizle
    if 'id' in df.columns:
        df = df.drop(columns=['id'])

    print(f"âœ… {len(df)} satÄ±r veri ile eÄŸitim baÅŸlÄ±yor...")

    # 2. Veri Ã–n Ä°ÅŸleme (Preprocessing)
    label_encoders = {}
    categorical_columns = df.select_dtypes(include=['object']).columns

    for col in categorical_columns:
        le = LabelEncoder()
        df[col] = df[col].astype(str)
        df[col] = le.fit_transform(df[col])
        label_encoders[col] = le

    # Hedef ve Ã–zellik AyrÄ±mÄ± (SÃ¼tun isimlerinin kÃ¼Ã§Ã¼k harf olduÄŸundan emin ol)
    X = df.drop(columns=['exam_score'])
    y = df['exam_score']

    # BÃ¶lme (%80 EÄŸitim, %20 Test)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # 3. Modeli EÄŸit (Daha hassas olmasÄ± iÃ§in n_estimators artÄ±rÄ±labilir)
    print("ğŸ§  Yapay Zeka modeli eÄŸitiliyor (Random Forest - Balanced)...")
    model = RandomForestRegressor(n_estimators=150, random_state=42, min_samples_split=5)
    model.fit(X_train, y_train)

    # 4. Test Et
    predictions = model.predict(X_test)
    mae = mean_absolute_error(y_test, predictions)
    r2 = r2_score(y_test, predictions)

    print(f"\nğŸ“Š --- Yeni Model BaÅŸarÄ± Raporu ---")
    print(f"Ortalama Hata PayÄ± (MAE): {mae:.2f} puan")
    print(f"Model DoÄŸruluÄŸu (R2 Score): {r2:.2f}")

    # 5. Kaydet
    if not os.path.exists(MODEL_DIR):
        os.makedirs(MODEL_DIR)

    joblib.dump(model, MODEL_PATH)
    joblib.dump(label_encoders, ENCODERS_PATH)

    metrics_data = {
        "mae": mae,
        "r2": r2,
        "last_trained": pd.Timestamp.now().strftime("%d-%m-%Y %H:%M")
    }
    with open(METRICS_PATH, "w") as f:
        json.dump(metrics_data, f)

    print(f"\nğŸ’¾ Yeni model ve metrikler kaydedildi: {MODEL_DIR}")
    print("âœ… ArtÄ±k dashboard Ã¼zerinden en kÃ¶tÃ¼ senaryolarÄ± test edebilirsiniz!")

if __name__ == "__main__":
    train_and_save_model()